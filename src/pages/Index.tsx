import { useState } from "react";
import { Button } from "@/components/ui/button";
import { Badge } from "@/components/ui/badge";
import { Card, CardContent } from "@/components/ui/card";
import { Tabs, TabsContent, TabsList, TabsTrigger } from "@/components/ui/tabs";
import AgentForm from "@/components/AgentForm";
import CodeViewer from "@/components/CodeViewer";
import VoiceLearningInterface from "@/components/voice/VoiceLearningInterface";
import EnhancedVoiceLearning from "@/components/voice/EnhancedVoiceLearning";
import SemanticSearchPanel from "@/components/voice/SemanticSearchPanel";
import LearningPathManager from "@/components/voice/LearningPathManager";
import { Bot, Sparkles, Zap, Github, Database, Shield, Mic, Code, FileCode, Download, Brain, Search, Map, MessageCircle } from "lucide-react";
import { useToast } from "@/hooks/use-toast";

interface AgentFormData {
  name: string;
  instructions: string;
  model: string;
  voice: string;
  description: string;
  tools: string[];
}

const generateAgentCode = (data: AgentFormData): string => {
  const toolsSetup = data.tools.length > 0 ? `
    tools=[
        ${data.tools.map(tool => `{"type": "${tool}"}`).join(',\n        ')}
    ],` : '';

  return `#!/usr/bin/env python3
"""
${data.name} - OpenAI TTS Agent
Generated by TTS Agent Forge

This agent uses OpenAI's Assistant API with Text-to-Speech capabilities.
"""

import os
import openai
from openai import OpenAI
from dotenv import load_dotenv
import tempfile
import pygame
import time

# Load environment variables
load_dotenv()

class TTSAgent:
    def __init__(self):
        """Initialize the TTS Agent with OpenAI client."""
        self.client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.assistant = None
        self.thread = None
        
        # Initialize pygame for audio playback
        pygame.mixer.init()
        
        # Agent configuration
        self.name = "${data.name}"
        self.instructions = """${data.instructions}
        
${data.description ? `Additional context: ${data.description}` : ''}

Always provide helpful, clear responses. Your responses will be converted to speech, so write in a conversational tone."""
        self.model = "${data.model}"
        self.voice = "${data.voice}"
        
    def create_assistant(self):
        """Create or retrieve the OpenAI Assistant."""
        try:
            self.assistant = self.client.beta.assistants.create(
                name=self.name,
                instructions=self.instructions,
                model=self.model,${toolsSetup}
            )
            print(f"‚úÖ Assistant '{self.name}' created successfully!")
            print(f"üì± Assistant ID: {self.assistant.id}")
            return True
        except Exception as e:
            print(f"‚ùå Error creating assistant: {e}")
            return False
    
    def create_thread(self):
        """Create a new conversation thread."""
        try:
            self.thread = self.client.beta.threads.create()
            print(f"üí¨ Thread created: {self.thread.id}")
            return True
        except Exception as e:
            print(f"‚ùå Error creating thread: {e}")
            return False
    
    def text_to_speech(self, text):
        """Convert text to speech and play it."""
        try:
            # Generate speech using OpenAI TTS
            response = self.client.audio.speech.create(
                model="tts-1",
                voice=self.voice,
                input=text
            )
            
            # Save to temporary file
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp_file:
                response.stream_to_file(tmp_file.name)
                
                # Play the audio
                pygame.mixer.music.load(tmp_file.name)
                pygame.mixer.music.play()
                
                # Wait for playback to complete
                while pygame.mixer.music.get_busy():
                    pygame.time.wait(100)
                    
                # Clean up
                os.unlink(tmp_file.name)
                
        except Exception as e:
            print(f"‚ùå TTS Error: {e}")
    
    def send_message(self, message):
        """Send a message and get response with TTS."""
        try:
            # Add message to thread
            self.client.beta.threads.messages.create(
                thread_id=self.thread.id,
                role="user",
                content=message
            )
            
            # Run the assistant
            run = self.client.beta.threads.runs.create(
                thread_id=self.thread.id,
                assistant_id=self.assistant.id
            )
            
            # Wait for completion
            while run.status in ['queued', 'in_progress']:
                time.sleep(1)
                run = self.client.beta.threads.runs.retrieve(
                    thread_id=self.thread.id,
                    run_id=run.id
                )
            
            if run.status == 'completed':
                # Get the response
                messages = self.client.beta.threads.messages.list(
                    thread_id=self.thread.id
                )
                
                response = messages.data[0].content[0].text.value
                print(f"ü§ñ {self.name}: {response}")
                
                # Convert to speech and play
                print("üîä Converting to speech...")
                self.text_to_speech(response)
                
                return response
            else:
                print(f"‚ùå Run failed with status: {run.status}")
                return None
                
        except Exception as e:
            print(f"‚ùå Error sending message: {e}")
            return None
    
    def chat(self):
        """Start interactive chat session."""
        print(f"üé§ Starting chat with {self.name}")
        print("üí° Type 'quit' to exit")
        print("-" * 50)
        
        while True:
            user_input = input("\\nüë§ You: ").strip()
            
            if user_input.lower() in ['quit', 'exit', 'bye']:
                print(f"üëã Goodbye! Thanks for chatting with {self.name}")
                break
                
            if user_input:
                self.send_message(user_input)

def main():
    """Main function to run the TTS Agent."""
    print("üöÄ TTS Agent Forge - ${data.name}")
    print("=" * 50)
    
    # Check for OpenAI API key
    if not os.getenv('OPENAI_API_KEY'):
        print("‚ùå Error: OPENAI_API_KEY not found!")
        print("üí° Set your API key: export OPENAI_API_KEY='your-key-here'")
        return
    
    # Initialize agent
    agent = TTSAgent()
    
    # Create assistant and thread
    if agent.create_assistant() and agent.create_thread():
        print("‚úÖ Agent setup complete!")
        
        # Start chat
        agent.chat()
    else:
        print("‚ùå Failed to initialize agent")

if __name__ == "__main__":
    main()
`;
};

export default function Index() {
  const [agentCode, setAgentCode] = useState<string>("");
  const [agentName, setAgentName] = useState<string>("");
  const [isGenerating, setIsGenerating] = useState(false);
  const [showCode, setShowCode] = useState(false);
  const { toast } = useToast();

  const handleFormSubmit = async (data: AgentFormData) => {
    setIsGenerating(true);
    setAgentName(data.name);
    
    // Simulate API call delay
    await new Promise(resolve => setTimeout(resolve, 2000));
    
    const code = generateAgentCode(data);
    setAgentCode(code);
    setShowCode(true);
    setIsGenerating(false);
    
    toast({
      title: "Agent Generated!",
      description: `${data.name} is ready to use with ${data.voice} voice.`,
    });
  };

  const features = [
    {
      icon: Bot,
      title: "AI Assistant Creation",
      description: "Generate OpenAI assistants with custom instructions and personalities"
    },
    {
      icon: Mic,
      title: "Text-to-Speech",
      description: "Built-in TTS with 6 voice options including male, female, and neutral tones"
    },
    {
      icon: Code,
      title: "Ready-to-Run Code",
      description: "Complete Python code with dependencies and setup instructions"
    },
    {
      icon: Zap,
      title: "Cost Optimized",
      description: "Uses GPT-4o Mini for efficiency - typically $0.01-0.05 per conversation"
    },
    {
      icon: Shield,
      title: "Secure API Handling",
      description: "Backend integration keeps your OpenAI API keys safe"
    },
    {
      icon: Download,
      title: "Export Options",
      description: "Download as ZIP, copy code, or export directly to GitHub"
    }
  ];

  return (
    <div className="min-h-screen bg-gradient-hero">
      {/* Hero Section */}
      <div className="relative overflow-hidden">
        <div className="absolute inset-0 bg-gradient-to-br from-primary/10 via-transparent to-primary-glow/10" />
        
        <div className="relative container mx-auto px-4 py-16">
          <div className="text-center max-w-4xl mx-auto mb-16">
            <div className="flex justify-center mb-6">
              <Badge variant="secondary" className="px-4 py-2 text-sm font-medium">
                <Sparkles className="h-4 w-4 mr-2" />
                No-Code AI Agent Builder
              </Badge>
            </div>
            
            <h1 className="text-4xl md:text-6xl font-bold mb-6 bg-gradient-primary bg-clip-text text-transparent">
              TTS Agent Forge
            </h1>
            
            <p className="text-xl md:text-2xl text-muted-foreground mb-8 max-w-3xl mx-auto">
              Create OpenAI assistants with Text-to-Speech in minutes. 
              Just describe what you want - we'll generate the complete Python code.
            </p>
            
            <div className="flex flex-wrap justify-center gap-4 mb-12">
              <Badge variant="outline" className="px-3 py-1">
                <FileCode className="h-3 w-3 mr-1" />
                Python Ready
              </Badge>
              <Badge variant="outline" className="px-3 py-1">
                <Database className="h-3 w-3 mr-1" />
                Supabase Integration
              </Badge>
              <Badge variant="outline" className="px-3 py-1">
                <Github className="h-3 w-3 mr-1" />
                GitHub Export
              </Badge>
            </div>
          </div>

          {/* Features Grid */}
          <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6 mb-16 max-w-6xl mx-auto">
            {features.map((feature, index) => {
              const Icon = feature.icon;
              return (
                <Card key={index} className="bg-card/50 backdrop-blur-sm border-border/50 hover:bg-card/80 transition-all duration-300 group">
                  <CardContent className="p-6">
                    <div className="flex items-start gap-4">
                      <div className="p-2 rounded-lg bg-primary/10 group-hover:bg-primary/20 transition-colors">
                        <Icon className="h-5 w-5 text-primary" />
                      </div>
                      <div>
                        <h3 className="font-semibold mb-2 text-foreground">
                          {feature.title}
                        </h3>
                        <p className="text-sm text-muted-foreground">
                          {feature.description}
                        </p>
                      </div>
                    </div>
                  </CardContent>
                </Card>
              );
            })}
          </div>

          {/* Enhanced Interface with Tabs */}
          <div className="max-w-7xl mx-auto mb-16">
            <Tabs defaultValue="builder" className="w-full">
              <TabsList className="grid w-full grid-cols-5 mb-8">
                <TabsTrigger value="builder" className="flex items-center gap-2">
                  <Code className="h-4 w-4" />
                  Agent Builder
                </TabsTrigger>
                <TabsTrigger value="voice" className="flex items-center gap-2">
                  <Brain className="h-4 w-4" />
                  Voice Learning
                </TabsTrigger>
                <TabsTrigger value="enhanced-voice" className="flex items-center gap-2">
                  <MessageCircle className="h-4 w-4" />
                  AI Voice Chat
                </TabsTrigger>
                <TabsTrigger value="search" className="flex items-center gap-2">
                  <Search className="h-4 w-4" />
                  Semantic Search
                </TabsTrigger>
                <TabsTrigger value="paths" className="flex items-center gap-2">
                  <Map className="h-4 w-4" />
                  Learning Paths
                </TabsTrigger>
              </TabsList>

              <TabsContent value="builder" className="space-y-8">
                <AgentForm onSubmit={handleFormSubmit} isGenerating={isGenerating} />
                {showCode && (
                  <CodeViewer 
                    agentCode={agentCode} 
                    agentName={agentName}
                    isVisible={showCode}
                  />
                )}
              </TabsContent>

              <TabsContent value="voice">
                <VoiceLearningInterface specialtyFocus="general" />
              </TabsContent>

              <TabsContent value="enhanced-voice">
                <EnhancedVoiceLearning specialtyFocus="general" />
              </TabsContent>

              <TabsContent value="search">
                <SemanticSearchPanel />
              </TabsContent>

              <TabsContent value="paths">
                <LearningPathManager />
              </TabsContent>
            </Tabs>
          </div>
        </div>
      </div>

      {/* Supabase Integration Notice */}
      <div className="border-t border-border/50 bg-muted/30 backdrop-blur-sm">
        <div className="container mx-auto px-4 py-8">
          <div className="flex flex-col md:flex-row items-center justify-between gap-6">
            <div className="flex items-center gap-4">
              <div className="p-3 rounded-lg bg-primary/10">
                <Database className="h-6 w-6 text-primary" />
              </div>
              <div>
                <h3 className="font-semibold text-foreground">Ready for Backend Features?</h3>
                <p className="text-muted-foreground text-sm">
                  Connect Supabase to enable authentication, agent storage, and secure OpenAI API calls
                </p>
              </div>
            </div>
            <Button variant="hero" size="lg" className="whitespace-nowrap">
              <Sparkles className="h-4 w-4" />
              Connect Supabase
            </Button>
          </div>
        </div>
      </div>
    </div>
  );
}
